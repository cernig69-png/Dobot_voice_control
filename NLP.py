import queue
import sys
import time
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write as wav_write
from faster_whisper import WhisperModel
from pathlib import Path

# ---------- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏Å ----------
SAMPLE_RATE = 16000      # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Hz)
CHANNELS = 1             # ‡πÇ‡∏°‡πÇ‡∏ô‡∏û‡∏≠
MODEL_SIZE = "small"     # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ: tiny, base, small, medium, large-v3 (‡πÉ‡∏´‡∏ç‡πà=‡πÅ‡∏°‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏ä‡πâ‡∏≤/‡∏Å‡∏¥‡∏ô‡πÅ‡∏£‡∏°)
LANGUAGE = "en"          # "th" = ‡πÑ‡∏ó‡∏¢ (‡∏à‡∏∞ auto ‡∏Å‡πá‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà None)
RECORD_SECONDS = 6       # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏≠‡∏±‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
OUT_WAV = Path("record.wav")

# ---------- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏¥‡∏ß‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á ----------
q = queue.Queue()

def audio_callback(indata, frames, time_info, status):
    if status:
        print(status, file=sys.stderr)
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float32 mono
    q.put(indata.copy())

def record_to_wav(duration=RECORD_SECONDS):
    print(f"üéôÔ∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á {duration} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ... (‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)")
    frames = []
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype="float32",
                        callback=audio_callback):
        start = time.time()
        while time.time() - start < duration:
            frames.append(q.get())
    audio = np.concatenate(frames, axis=0)

    # Normalize ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô int16 ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô WAV
    audio_int16 = np.int16(audio / np.max(np.abs(audio)) * 32767) if np.max(np.abs(audio)) > 0 else np.int16(audio)
    wav_write(OUT_WAV, SAMPLE_RATE, audio_int16)
    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô: {OUT_WAV.resolve()}")

def transcribe_wav(path=OUT_WAV, model_size=MODEL_SIZE, language=LANGUAGE):
    print("üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢)...")
    # device="cpu" ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á; ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏à‡∏≠ NVIDIA ‡πÉ‡∏ä‡πâ device="cuda" ‡∏à‡∏∞‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    model = WhisperModel(model_size, device="cpu", compute_type="int8")  # ‡∏•‡∏≠‡∏á int8 ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÅ‡∏£‡∏°/‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô

    print("üîé ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
    segments, info = model.transcribe(str(path), language=language, vad_filter=True)

    print(f"‚ÑπÔ∏è  Language: {info.language}, Prob: {info.language_probability:.2f}")
    text = []
    for seg in segments:
        # ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ß‡∏•‡∏≤‡∏ö‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π‡πÑ‡∏ó‡∏°‡πå‡πÑ‡∏•‡∏ô‡πå
        print(f"[{seg.start:6.2f} ‚Üí {seg.end:6.2f}] {seg.text}")
        text.append(seg.text)

    result = "".join(text).strip()
    print("\nüìÑ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏ß‡∏°:")
    print(result)
    return result

if __name__ == "__main__":
    try:
        while True:
            # ‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏î
            input("\n‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡∏´‡∏£‡∏∑‡∏≠ Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): ")
            record_to_wav(RECORD_SECONDS)
            transcribe_wav()
    except KeyboardInterrupt:
        print("\nüëã ‡∏≠‡∏≠‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÅ‡∏•‡πâ‡∏ß")
